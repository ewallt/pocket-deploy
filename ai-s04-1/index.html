<!-- /pocket-deploy/ai-s04-1/index.html -->
<!DOCTYPE html>
<html lang="en">
<head><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>AI s04 — Part 1: The Rise of Deliberate Reasoning</title>
<style>
:root{--bg:#0b1020;--panel:#0f172a;--ink:#e5e7eb;--muted:#94a3b8;--brand:#60a5fa;--border:#1f2940}
@media(prefers-color-scheme:light){:root{--bg:#f5f7fb;--panel:#fff;--ink:#1b2a41;--muted:#34495e;--brand:#2563eb;--border:#e3e9f3}}
*{box-sizing:border-box}body{margin:0;background:var(--bg);color:var(--ink);font:16px/1.6 system-ui,-apple-system,Segoe UI,Inter,Arial;padding:2rem}
.c{max-width:880px;margin:0 auto;background:var(--panel);border:1px solid var(--border);border-radius:14px;box-shadow:0 6px 24px rgba(0,0,0,.25)}
.nav{display:flex;gap:.5rem;flex-wrap:wrap;padding:.75rem;border-bottom:1px solid var(--border)}.nav a{padding:.45rem .7rem;border:1px solid var(--border);border-radius:999px;text-decoration:none;color:var(--ink)}.nav a:hover{border-color:var(--brand);color:var(--brand)}
.h{padding:1.25rem 1.5rem}.intro{color:var(--muted);font-style:italic;margin:.25rem 0 1rem}
.p{padding:0 1.5rem 1.4rem}.p p{margin:1.05rem 0}
.f{padding:1rem 1.5rem;border-top:1px solid var(--border);color:var(--muted);font-size:.95rem}
table{width:100%;border-collapse:collapse;margin-top:.4rem}th,td{border:1px solid var(--border);padding:.4rem;text-align:left}th{color:var(--brand)}
</style></head>
<body><article class="c">
<nav class="nav">
  <a href="/pocket-deploy/dashboard-ai-s04/">← Dashboard</a>
  <a href="/pocket-deploy/ai-s04-2/">Next →</a>
</nav>
<header class="h"><h1>The Rise of Deliberate Reasoning — Part 1</h1><p class="intro">No, the post-scale era did not abandon transformers; it reoriented them from faster answers to better thinking by spending extra compute at inference time.</p></header>
<section class="p">
<p><strong>Context setup.</strong> After years when bigger pretraining largely predicted gains, the frontier shifted to test-time strategies that allocate effort dynamically. Models began writing intermediate scratchpads, branching thoughts, and verifying steps before committing to final tokens. This mirrored practices in mathematics and programming: show work, check invariants, and prune dead ends. The historical turn was conceptual—quality emerged from process, not only from parameters—and practical, because test-time knobs were cheaper to change than pretraining runs.</p>
<p><strong>Sequential explanation (stage 1 — scratchpads).</strong> Early chain-of-thought prompted models to externalize reasoning, but results were brittle. Deliberate systems normalized internal workspaces: they reserve tokens for plans, derive subgoals, and mark checkpoints the model can revisit. The pattern is: propose, elaborate, critique, then answer. By decoupling “thinking tokens” from “final tokens,” systems trade latency for reliability, especially in math, code, and multi-hop tasks where silent failures had previously masqueraded as fluency.</p>
<p><strong>Stage 2 — test-time scaling.</strong> Instead of one forward pass, models generate multiple candidate traces and use voting, scoring, or reward models to select the best. Sampling temperature, branching factor, and verification depth act like dials. This increases compute linearly with the number of traces, but the accuracy curve bends superlinearly on certain tasks. The operational insight is that inference budgets can be proportional to difficulty: spend more when uncertainty is high and less when prompts are routine.</p>
<p><strong>Stage 3 — self-critique and tools.</strong> Reasoning improved further when models could call specialist tools mid-deliberation—calculators for arithmetic, compilers for code, browsers for evidence. Tool calls function as external assertions; the model anchors claims to results it can check. Self-critique loops ask the model to locate contradictions or missing premises, then patch the trace. The rhythm becomes programmatic: plan → fetch → compute → reconcile → finalize, with guardrails that watch the process rather than only the product.</p>
<p><strong>Parallel comparisons.</strong> Traditional one-shot decoding is fast but opaque; deliberate decoding is slower but auditable. Classic RLHF emphasized endpoint behavior; process-based feedback rewards intermediate discipline. Pure parametric memory risks stale facts; tool-assisted reasoning updates itself on demand. The trade-offs resemble human workflows: a quick reply, a careful essay, or a lab report with measurements. Deliberate systems choose among modes instead of forcing one default style.</p>
<p><strong>Sectional synthesis — modes of reasoning.</strong></p>
<table>
<tr><th>Mode</th><th>Strength</th><th>When to use</th></tr>
<tr><td>One-shot</td><td>Low latency</td><td>Routine Q&A, small stakes</td></tr>
<tr><td>Deliberate</td><td>Higher reliability</td><td>Math, code, planning</td></tr>
<tr><td>Tool-augmented</td><td>Verifiable results</td><td>Facts, calculations, retrieval</td></tr>
</table>
<p><strong>Conclusion.</strong> The meaning of “intelligence” in language models broadened: not merely predicting the next word, but orchestrating a process that earns the right answer. By budgeting thought, surfacing steps, and consulting tools, deliberate models traded raw speed for trust and transformed inference into a transparent craft.</p>
</section>
<footer class="f">Sources note: general developments in deliberate/test-time reasoning, scratchpads, self-critique, and tool use circa 2024–2025.</footer>
</article></body></html>
