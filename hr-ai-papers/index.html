<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Landmark AI Papers: A Retrospective</title>
    <style>
        :root {
            --bg-gradient: linear-gradient(135deg,#2c3e50 0%,#34495e 100%);
            --accent-1: #e74c3c;
            --accent-2: #c03b2b;
            --btn-gradient: linear-gradient(45deg,#e74c3c,#c0392b);
            --accent-1-rgb: 231, 76, 60;
            --accent-warning: #ffc107;
            --accent-warning-rgb: 255, 193, 7;
            --text-primary: #ecf0f1;
            --text-secondary: #bdc3c7;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', serif;
            background: var(--bg-gradient);
            color: var(--text-primary);
            min-height: 100vh;
        }

        .header {
            background: rgba(0,0,0,0.3);
            padding: 2rem;
            text-align: center;
            border-bottom: 3px solid var(--accent-1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-top: 0;
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(45deg, var(--accent-1), var(--accent-2));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.5);
            filter: drop-shadow(0 0 15px rgba(var(--accent-1-rgb), 0.3));
        }

        .header p {
            font-size: 1.2rem;
            color: var(--text-secondary);
            font-style: italic;
        }

        .nav-tabs {
            display: flex;
            justify-content: center;
            align-items: center;
            background: rgba(0,0,0,0.2);
            padding: 1rem;
            gap: 1rem;
            flex-wrap: wrap;
        }
        
        /* --- FINAL BUTTON RULES START --- */

        /* Base style for ALL buttons */
        .tab-button, #settings-btn, .sector-button {
            padding: 12px 24px;
            background: var(--ui-background);
            border: none;
            color: var(--text-primary);
            cursor: pointer;
            border-radius: 5px;
            font-size: 1rem;
            transition: all 0.3s ease;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        /* Specific settings for the icon */
        #settings-btn {
            font-size: 1.2rem;
            padding: 10px 15px;
        }

        /* HOVER state for buttons */
        .tab-button:hover, .sector-button:hover, #settings-btn:hover {
            background: var(--btn-gradient);
            transform: translateY(-2px);
            color: var(--btn-text-hover);
        }

        /* ACTIVE state for selected buttons */
        .tab-button.active, .sector-button.active {
            background: var(--btn-gradient);
            border-color: var(--accent-2);
            transform: translateY(-2px);
            color: var(--btn-text-active);
        }
        
        /* --- FINAL BUTTON RULES END --- */

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }
        
        /* Modal Styles */
        .modal-overlay {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.7);
            justify-content: center;
            align-items: center;
            animation: fadeIn 0.3s ease;
        }

        .modal-overlay.show {
            display: flex;
        }

        .modal-content {
            background: #2c3e50;
            padding: 2rem;
            border-radius: 10px;
            border: 1px solid rgba(255,255,255,0.2);
            box-shadow: 0 8px 32px rgba(0,0,0,0.5);
            text-align: center;
            position: relative;
            width: 90%;
            max-width: 400px;
        }

        .modal-content h3 {
            color: var(--accent-1);
            margin-bottom: 1.5rem;
            font-size: 1.5rem;
        }
        
        .modal-content label {
            font-size: 1.1rem;
            margin-right: 10px;
        }

        #theme-select {
            background-color: var(--ui-background);
            color: var(--text-primary);
            border: 1px solid var(--accent-2);
            border-radius: 5px;
            padding: 8px;
            font-size: 1rem;
        }

        .close-btn {
            position: absolute;
            top: 10px;
            right: 15px;
            color: #aaa;
            font-size: 28px;
            font-weight: bold;
            background: none;
            border: none;
            cursor: pointer;
        }

        .close-btn:hover,
        .close-btn:focus {
            color: var(--text-primary);
            text-decoration: none;
        }

        .tab-content {
            display: none;
            animation: fadeIn 0.5s ease-in;
        }

        .tab-content.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .section-card {
            background: rgba(255,255,255,0.05);
            backdrop-filter: blur(10px);
            border-radius: 10px;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid rgba(255,255,255,0.2);
            box-shadow: 0 8px 32px rgba(0,0,0,0.3);
        }

        .section-title {
            color: var(--accent-1);
            font-size: 1.8rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid var(--accent-1);
        }

        .subsection {
            margin: 1.5rem 0;
        }

        .subsection h3 {
            color: var(--accent-1);
            font-size: 1.3rem;
            margin-bottom: 0.8rem;
        }

        .subsection h4 {
            color: var(--accent-2);
            font-size: 1.1rem;
            margin: 1rem 0 0.5rem 0;
        }

        .sector-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin-top: 2rem;
        }

        .sector-card {
            background: rgba(255,255,255,0.05);
            border-radius: 8px;
            padding: 1.5rem;
            border-left: 4px solid var(--accent-1);
            transition: transform 0.3s ease;
            border: 1px solid rgba(255,255,255,0.1);
        }

        .sector-card:hover {
            transform: translateY(-5px);
            background: rgba(255,255,255,0.1);
        }

        .sector-name {
            color: var(--accent-1);
            font-size: 1.4rem;
            font-weight: bold;
            margin-bottom: 0.5rem;
        }

        .casualties-highlight {
            background: rgba(var(--accent-warning-rgb), 0.15);
            padding: 1rem;
            border-radius: 5px;
            border-left: 4px solid var(--accent-warning);
            margin: 1rem 0;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1rem;
            margin: 1.5rem 0;
        }

           .stat-card {
            background: var(--ui-background-accent);
            padding: 1.5rem;
            border-radius: 8px;
            text-align: center;
            border: 1px solid rgba(255,255,255,0.2);
        }

        .stat-number {
            font-size: 2rem;
            font-weight: bold;
            color: var(--accent-1);
            display: block;
        }

        .stat-label {
            color: var(--text-secondary);
            margin-top: 0.5rem;
        }
        
        .timeline {
            position: relative;
            padding-left: 2rem;
            margin-top: 2rem;
        }

        .timeline::before {
            content: '';
            position: absolute;
            left: 0;
            top: 0;
            bottom: 0;
            width: 2px;
            background: var(--accent-1);
        }

        .timeline-item {
            position: relative;
            margin-bottom: 2rem;
            padding-left: 2rem;
        }

        .timeline-item::before {
            content: '';
            position: absolute;
            left: -2.05rem;
            top: 5px;
            width: 12px;
            height: 12px;
            background: var(--accent-1);
            border-radius: 50%;
            border: 2px solid var(--ui-background);
        }

        .timeline-time {
            color: var(--accent-1);
            font-weight: bold;
            font-size: 1.1rem;
            margin-bottom: 0.5rem;
        }

        .search-box {
            width: 100%;
            padding: 12px;
            font-size: 1rem;
            border: none;
            border-radius: 5px;
            background: rgba(255,255,255,0.1);
            color: var(--text-primary);
            margin-bottom: 2rem;
        }

        .search-box::placeholder {
            color: var(--text-secondary);
        }

        .highlight {
            background: rgba(var(--accent-1-rgb), 0.3);
            padding: 2px 4px;
            border-radius: 3px;
        }

        .interactive-map {
            background: var(--container-background-subtle);
            padding: 2rem;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 2rem;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .sector-buttons {
            display: flex;
            justify-content: center;
            gap: 1rem;
            flex-wrap: wrap;
            margin-top: 1rem;
        }

        .sector-detail {
            display: none;
            margin-top: 2rem;
            padding: 1.5rem;
            background: rgba(255,255,255,0.05);
            border-radius: 8px;
        }

        .sector-detail.show {
            display: block;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 2rem;
            }
            .nav-tabs {
                flex-direction: column;
                align-items: center;
            }
            .container {
                padding: 1rem;
            }
            .sector-grid {
                grid-template-columns: 1fr;
            }
            .stats-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
    <script>
    // Self-executing function to manage all theme logic.
    (function() {
        const DEFAULT_THEME_NAME = 'cyber-night';
    
        let THEMES = {
            'cyber-night': {
                '--bg-gradient': 'linear-gradient(135deg,#0a0a23 0%,#1a1a3a 50%,#2e2e5e 100%)',
                '--accent-1': '#a8b8d0', '--accent-1-rgb': '168, 184, 208',
                '--accent-2': '#8899b3',
                '--btn-gradient': 'linear-gradient(45deg,#1a1a3a,#2e2e5e)',
                '--accent-warning': '#e8b339',
                '--accent-warning-rgb': '232, 179, 57',
                '--ui-background': '#34495e',
                '--ui-background-accent': 'rgba(52, 73, 94, 0.8)',
                '--container-background-subtle': 'rgba(0, 0, 0, 0.3)',
                '--btn-text-active': '#ecf0f1',
                '--btn-text-hover': '#ecf0f1'
            },
            'teal-matrix': {
                '--bg-gradient': 'linear-gradient(135deg,#0a231c 0%,#1a3a31 50%,#2e5e50 100%)',
                '--accent-1': '#ace0d5', '--accent-1-rgb': '172, 224, 213',
                '--accent-2': '#92b3a9',
                '--btn-gradient': 'linear-gradient(45deg,#1a3a31,#2e5e50)',
                '--accent-warning': '#e8b339',
                '--accent-warning-rgb': '232, 179, 57',
                '--ui-background': '#345e55',
                '--ui-background-accent': 'rgba(52, 94, 85, 0.8)',
                '--container-background-subtle': 'rgba(0, 0, 0, 0.3)',
                '--btn-text-active': '#ecf0f1',
                '--btn-text-hover': '#ecf0f1'
            },
            'red-alert': {
                '--bg-gradient': 'linear-gradient(135deg,#0a0a23 0%,#1a1a3a 50%,#2e2e5e 100%)',
                '--ui-background': '#34495e',
                '--ui-background-accent': 'rgba(52, 73, 94, 0.8)',
                '--container-background-subtle': 'rgba(0, 0, 0, 0.3)',
                '--accent-1': '#e74c3c',
                '--accent-2': '#c03b2b',
                '--btn-gradient': 'linear-gradient(45deg,#e74c3c,#c0392b)',
                '--accent-1-rgb': '231, 76, 60',
                '--accent-warning': '#e8b339',
                '--accent-warning-rgb': '232, 179, 57',
                '--btn-text-active': '#ffffff',
                '--btn-text-hover': '#ffffff'
            },
            'scorched-gold': {
                '--bg-gradient': 'linear-gradient(135deg,#0a231f 0%,#193a33 50%,#2e5e54 100%)',
                '--ui-background': '#345e56',
                '--ui-background-accent': 'rgba(52, 94, 86, 0.8)',
                '--container-background-subtle': 'rgba(0, 0, 0, 0.3)',
                '--accent-1': '#f0c475',
                '--accent-2': '#d4a24c',
                '--btn-gradient': 'linear-gradient(45deg,#f0c475,#d4a24c)',
                '--accent-1-rgb': '240, 196, 117',
                '--btn-text-active': '#2a1d15',
                '--btn-text-hover': '#2a1d15',
                '--accent-warning': '#e8b339',
                '--accent-warning-rgb': '232, 179, 57'
            },            
            'emerald-cyber': {
                '--bg-gradient': 'linear-gradient(135deg,#0a230a 0%,#1a3a1a 50%,#2e5e2e 100%)',
                '--accent-1': '#a8d0b8', '--accent-1-rgb': '168, 208, 184',
                '--accent-2': '#6a947a', '--btn-gradient': 'linear-gradient(45deg,#1a3a1a,#2e5e2e)',
                '--accent-warning': '#ffc107', '--accent-warning-rgb': '255, 193, 7',
                '--ui-background': '#34495e',
                '--ui-background-accent': 'rgba(52, 73, 94, 0.8)',
                '--container-background-subtle': 'rgba(0, 0, 0, 0.3)',
                '--btn-text-active': '#ecf0f1',
                '--btn-text-hover': '#ecf0f1'
            },            
            'emerald-night': {
                '--bg-gradient': 'linear-gradient(135deg,#0a230a 0%,#1a3a1a 50%,#2e5e2e 100%)',
                '--accent-1': '#a8d0b8', '--accent-1-rgb': '168, 208, 184',
                '--accent-2': '#6a947a',
                '--btn-gradient': 'linear-gradient(45deg,#1a3a1a,#2e5e2e)',
                '--accent-warning': '#ffc107', '--accent-warning-rgb': '255, 193, 7',
                '--ui-background': '#345e49',
                '--ui-background-accent': 'rgba(52, 94, 73, 0.8)',
                '--container-background-subtle': 'rgba(0, 0, 0, 0.3)',
                '--btn-text-active': '#ecf0f1',
                '--btn-text-hover': '#ecf0f1'
            }
        };
    
        function applyTheme(name) {
            const theme = THEMES[name];
            if (theme) {
                const root = document.documentElement;
                for (const [key, value] of Object.entries(theme)) {
                    root.style.setProperty(key, value);
                }
            }
        }
    
        window.setTheme = function(name) {
            applyTheme(name);
            localStorage.setItem('ai-papers-theme', name); // Changed storage key
        }
    
        const availableThemeNames = Object.keys(THEMES);
        const savedTheme = localStorage.getItem('ai-papers-theme'); // Changed storage key
        let themeToLoad = DEFAULT_THEME_NAME;

        if (savedTheme && availableThemeNames.includes(savedTheme)) {
            themeToLoad = savedTheme;
        }
        
        applyTheme(themeToLoad);
    
        document.addEventListener('DOMContentLoaded', () => {
            const themeSelect = document.getElementById('theme-select');
            if (themeSelect) {
                themeSelect.innerHTML = '';
                availableThemeNames.forEach(name => {
                    const option = document.createElement('option');
                    option.value = name;
                    option.textContent = name.replace(/-/g, ' ').replace(/\b\w/g, l => l.toUpperCase());
                    themeSelect.appendChild(option);
                });
                themeSelect.value = themeToLoad;
            }
        });
    })();
    </script>
</head>
<body>
    <div id="settings-modal" class="modal-overlay">
        <div class="modal-content">
            <button id="close-modal-btn" class="close-btn">&times;</button>
            <h3>Display Settings</h3>
            <label for="theme-select">Theme:</label>
            <select id="theme-select" onchange="setTheme(this.value)"></select>
        </div>
    </div>

    <div class="header">
        <h1>Landmark AI Papers</h1>
        <p>A Retrospective from 2035 • The Foundations of Modern AI</p>
    </div>

    <div class="nav-tabs">
        <button class="tab-button active" data-tab="timeline">Timeline</button>
        <button class="tab-button" data-tab="alexnet">AlexNet (2012)</button>
        <button class="tab-button" data-tab="gan">GANs (2014)</button>
        <button class="tab-button" data-tab="transformer">Transformer (2017)</button>
        <button class="tab-button" data-tab="bert">BERT (2018)</button>
        <button class="tab-button" data-tab="gpt3">GPT-3 (2020)</button>
        <button class="tab-button" data-tab="diffusion">Diffusion (2021)</button>
        <button id="settings-btn" title="Settings">⚙️</button>
    </div>

    <div class="container">
        <div id="timeline" class="tab-content active">
             <div class="section-card">
                <h2 class="section-title">A Timeline of Foundational Papers</h2>
                <p style="font-size: 1.1rem; line-height: 1.7;">Looking back, the rapid acceleration of AI in the 2020s was built upon a handful of pivotal breakthroughs. These key papers introduced the core architectures and techniques that defined the modern AI landscape, each one unlocking a new paradigm of capability.</p>
                <div class="timeline">
                    <div class="timeline-item">
                        <div class="timeline-time">2012</div>
                        <h4>ImageNet Classification (AlexNet)</h4>
                        <p>This paper proved that deep convolutional neural networks could vastly outperform existing methods in computer vision, kickstarting the deep learning revolution.</p>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-time">2014</div>
                        <h4>Generative Adversarial Networks (GANs)</h4>
                        <p>Introduced a novel framework where two neural networks, a generator and a discriminator, compete against each other. This unlocked an unprecedented ability to generate realistic, novel data, especially images.</p>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-time">2017</div>
                        <h4>Attention Is All You Need (Transformer)</h4>
                        <p>The single most important paper for modern AI. It introduced the Transformer architecture and its self-attention mechanism, which became the foundation for virtually all subsequent large language models.</p>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-time">2018</div>
                        <h4>BERT: Pre-training of Deep Bidirectional Transformers</h4>
                        <p>BERT demonstrated how to pre-train a Transformer model on a massive text corpus to understand context from both left-to-right and right-to-left, dramatically improving language understanding.</p>
                    </div>
                     <div class="timeline-item">
                        <div class="timeline-time">2020</div>
                        <h4>Language Models are Few-Shot Learners (GPT-3)</h4>
                        <p>This paper showed that by massively scaling up a Transformer model to 175 billion parameters, it could perform a wide range of tasks without any specific fine-tuning, exhibiting "in-context learning."</p>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-time">2021</div>
                        <h4>Denoising Diffusion Probabilistic Models</h4>
                        <p>While the core idea was from 2015, this and other papers from the early 2020s refined diffusion models, leading to a new generation of high-fidelity image synthesis models like DALL-E 2 and Midjourney.</p>
                    </div>
                </div>
            </div>
        </div>

        <div id="alexnet" class="tab-content">
            <div class="section-card">
                <h2 class="section-title">ImageNet Classification with Deep CNNs (2012)</h2>
                <div class="sector-grid">
                    <div class="sector-card">
                        <div class="sector-name">Core Contribution</div>
                        <p>The "AlexNet" architecture, a deep convolutional neural network (CNN), won the 2012 ImageNet challenge by a massive margin. It proved that deep learning was a viable, and superior, approach for complex computer vision tasks.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Key Innovations</div>
                        <p>It was the first to successfully use several key techniques together: the ReLU activation function for faster training, "dropout" to prevent overfitting, and GPU acceleration to handle the massive computational load.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Lasting Impact</div>
                        <p>This paper is widely credited with starting the "deep learning boom." Its success caused a massive shift in the AI research community, moving focus away from hand-crafted feature extractors and towards end-to-end deep learning.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="gan" class="tab-content">
            <div class="section-card">
                <h2 class="section-title">Generative Adversarial Networks (2014)</h2>
                <div class="sector-grid">
                    <div class="sector-card">
                        <div class="sector-name">Core Contribution</div>
                        <p>Introduced a novel framework where two networks, a **Generator** and a **Discriminator**, are trained simultaneously in a zero-sum game. The Generator tries to create realistic data, while the Discriminator tries to tell the fake data from real data.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">The "Counterfeiter" Analogy</div>
                        <p>The process is often compared to an art forger (Generator) trying to create fake paintings and an art critic (Discriminator) trying to detect them. As both get better, the forger's fakes become indistinguishable from the real thing.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Lasting Impact</div>
                        <p>GANs revolutionized the field of generative AI, leading to hyper-realistic image synthesis, "deepfakes," and advancements in data augmentation and unsupervised learning.</p>
                    </div>
                </div>
            </div>
        </div>

        <div id="transformer" class="tab-content">
            <div class="section-card">
                <h2 class="section-title">Attention Is All You Need (2017)</h2>
                <div class="sector-grid">
                    <div class="sector-card">
                        <div class="sector-name">Core Contribution</div>
                        <p>Introduced the **Transformer architecture**, which dispensed with the recurrent layers (RNNs/LSTMs) that were standard for language tasks. It relied entirely on a mechanism called **self-attention** to process all words in a sequence simultaneously.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">The Power of Attention</div>
                        <p>The self-attention mechanism allowed the model to weigh the influence of all other words in the input when encoding a specific word. This provided a much deeper understanding of context and long-range dependencies in language.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Lasting Impact</div>
                        <p>Arguably the most influential AI paper of the modern era. The Transformer's parallel processing capabilities and superior handling of context made it the foundational architecture for nearly all subsequent large-scale models, including GPT, BERT, and Gemini.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="bert" class="tab-content">
            <div class="section-card">
                <h2 class="section-title">BERT: Pre-training Deep Bidirectional Transformers (2018)</h2>
                <div class="sector-grid">
                    <div class="sector-card">
                        <div class="sector-name">Core Contribution</div>
                        <p>BERT (Bidirectional Encoder Representations from Transformers) introduced a method for pre-training a Transformer on a massive amount of text data to learn language representations that could be easily fine-tuned for a wide variety of tasks.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Bidirectional Context</div>
                        <p>Unlike earlier models that read text in one direction, BERT used a "Masked Language Model" objective to learn context from both the left and right side of a word simultaneously. This gave it a much deeper understanding of language nuance.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Lasting Impact</div>
                        <p>BERT set new state-of-the-art records on numerous natural language understanding benchmarks and was quickly integrated into products like Google Search. It solidified the "pre-train and fine-tune" paradigm as the dominant approach in NLP.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="gpt3" class="tab-content">
            <div class="section-card">
                <h2 class="section-title">Language Models are Few-Shot Learners (2020)</h2>
                <div class="sector-grid">
                    <div class="sector-card">
                        <div class="sector-name">Core Contribution</div>
                        <p>This paper demonstrated that by scaling up a Transformer-based language model to an unprecedented size (175 billion parameters), it gained the ability to perform a wide range of tasks without any task-specific training, a phenomenon called **in-context learning**.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">"Few-Shot" Learning</div>
                        <p>GPT-3 could be "programmed" simply by providing a few examples of a task in the prompt itself. For instance, you could give it two translated sentences and then a new sentence to translate, and it would understand the task.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Lasting Impact</div>
                        <p>GPT-3's incredible generative capabilities captured the public's imagination and launched the era of large-scale, general-purpose AI models. It showed that scale wasn't just about better performance, but about qualitatively new, emergent abilities.</p>
                    </div>
                </div>
            </div>
        </div>
        
        <div id="diffusion" class="tab-content">
            <div class="section-card">
                <h2 class="section-title">Denoising Diffusion Probabilistic Models (2021)</h2>
                <div class="sector-grid">
                    <div class="sector-card">
                        <div class="sector-name">Core Contribution</div>
                        <p>This paper, along with others around the same time, refined and popularized diffusion models. These models work by systematically adding noise to an image and then training a neural network to reverse the process, learning to generate an image from pure noise.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Superior Image Quality</div>
                        <p>Diffusion models proved to be capable of generating much higher-fidelity and more diverse images than the previous state-of-the-art (GANs). The step-by-step denoising process allowed for more stable training and greater creative control.</p>
                    </div>
                    <div class="sector-card">
                        <div class="sector-name">Lasting Impact</div>
                        <p>This work directly led to the explosion of text-to-image models like DALL-E 2, Midjourney, and Stable Diffusion, which transformed creative industries and became a cultural phenomenon in the mid-2020s.</p>
                    </div>
                </div>
            </div>
        </div>

        <div id="search" class="tab-content">
            <div class="section-card">
                <h2 class="section-title">Search the Knowledge Base</h2>
                <input type="text" id="searchInput" class="search-box" placeholder="Search for papers, authors, concepts...">
                
                <div id="searchResults">
                    <p style="text-align: center; color: var(--text-secondary); font-style: italic; margin: 2rem 0;">
                        Enter a search term above to explore the AI papers knowledge base.<br>
                        Try searching for: "Attention", "GAN", "GPT-3", "AlexNet", "Diffusion", etc.
                    </p>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Knowledge base for searching
        const knowledgeBase = {
            "Attention Is All You Need": "The 2017 paper by Vaswani et al. that introduced the Transformer architecture, which replaced recurrent and convolutional layers with self-attention mechanisms, enabling massive parallelization and superior performance on language tasks.",
            "Transformer": "The neural network architecture introduced in 'Attention Is All You Need'. Its self-attention mechanism became the foundational technology for modern large language models.",
            "AlexNet": "The deep convolutional neural network from the 2012 ImageNet paper by Krizhevsky et al. Its success kickstarted the deep learning revolution in computer vision.",
            "GANs": "Generative Adversarial Networks, introduced by Ian Goodfellow et al. in 2014. They consist of a 'generator' and a 'discriminator' that compete to produce highly realistic data.",
            "BERT": "A language model from 2018 by Devlin et al. that demonstrated the power of bidirectional pre-training to understand language context, setting new standards for natural language understanding.",
            "GPT-3": "The 175-billion parameter model from OpenAI's 2020 paper, 'Language Models are Few-Shot Learners'. It showed that scaling up models unlocked emergent abilities like in-context learning.",
            "Diffusion Models": "A class of generative models, refined in the early 2020s, that create data by reversing a gradual noising process. They became the state-of-the-art for high-fidelity image synthesis."
        };

        // Initialize the application
        document.addEventListener('DOMContentLoaded', function() {
            initializeTabs();
            initializeSectorButtons();
            initializeSearch();
            initializeModal();
        });

        function initializeModal() {
            const modal = document.getElementById('settings-modal');
            const openBtn = document.getElementById('settings-btn');
            const closeBtn = document.getElementById('close-modal-btn');

            if (modal && openBtn && closeBtn) {
                openBtn.addEventListener('click', () => modal.classList.add('show'));
                closeBtn.addEventListener('click', () => modal.classList.remove('show'));
                modal.addEventListener('click', (event) => {
                    if (event.target === modal) modal.classList.remove('show');
                });
            }
        }

        function initializeTabs() {
            const tabButtons = document.querySelectorAll('.tab-button');
            tabButtons.forEach(button => {
                button.addEventListener('click', function() {
                    const tabName = this.getAttribute('data-tab');
                    showTab(tabName);
                });
            });
        }

        function showTab(tabName) {
            try {
                document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));
                document.querySelectorAll('.tab-button').forEach(button => button.classList.remove('active'));
                document.getElementById(tabName).classList.add('active');
                document.querySelector(`[data-tab="${tabName}"]`).classList.add('active');
            } catch (error) { console.error('Error in showTab:', error); }
        }

        function initializeSectorButtons() {
            const sectorButtons = document.querySelectorAll('.sector-button');
            sectorButtons.forEach(button => {
                button.addEventListener('click', function() {
                    const sectorName = this.getAttribute('data-sector');
                    showSectorDetail(sectorName, this);
                });
            });
        }

        function showSectorDetail(sector, clickedButton) {
            try {
                document.querySelectorAll('.sector-detail').forEach(detail => detail.classList.remove('show'));
                document.querySelectorAll('.sector-button').forEach(button => button.classList.remove('active'));
                const targetDetail = document.getElementById(sector + '-detail');
                if (targetDetail) {
                    targetDetail.classList.add('show');
                    clickedButton.classList.add('active');
                }
            } catch (error) { console.error('Error in showSectorDetail:', error); }
        }

        function initializeSearch() {
            const searchInput = document.getElementById('searchInput');
            if (searchInput) {
                searchInput.addEventListener('keyup', searchContent);
            }
        }

        function searchContent() {
            try {
                const searchInput = document.getElementById('searchInput');
                const resultsDiv = document.getElementById('searchResults');
                if (!searchInput || !resultsDiv) return;
                
                const searchTerm = searchInput.value.toLowerCase();

                if (searchTerm.length < 2) {
                    resultsDiv.innerHTML = `<p style="text-align: center; color: var(--text-secondary); font-style: italic; margin: 2rem 0;">Enter a search term above to explore the AI papers knowledge base.<br>Try searching for: "Transformer", "GAN", "GPT-3", "AlexNet", "Diffusion", etc.</p>`;
                    return;
                }

                let results = [];
                for (const key in knowledgeBase) {
                    if (knowledgeBase.hasOwnProperty(key)) {
                        const value = knowledgeBase[key];
                        if (key.toLowerCase().includes(searchTerm) || value.toLowerCase().includes(searchTerm)) {
                            results.push({
                                title: key,
                                content: value,
                                relevance: key.toLowerCase().startsWith(searchTerm) ? 2 : 1
                            });
                        }
                    }
                }

                results.sort((a, b) => b.relevance - a.relevance);

                if (results.length === 0) {
                    resultsDiv.innerHTML = `<div class="section-card"><h3 style="color: var(--accent-1);">No results found for "${searchInput.value}"</h3><p>Try searching for papers, authors, or concepts.</p></div>`;
                    return;
                }

                let resultHTML = `<h3 style="color: var(--accent-1); margin-bottom: 1.5rem;">Search Results for "${searchInput.value}"</h3>`;
                for (let i = 0; i < results.length; i++) {
                    const result = results[i];
                    const highlightedContent = result.content.replace(new RegExp(searchTerm, 'gi'), `<span class="highlight">$&</span>`);
                    resultHTML += `<div style="background: rgba(255,255,255,0.05); padding: 1.5rem; border-radius: 8px; margin-bottom: 1rem; border-left: 4px solid var(--accent-1);"><h4 style="color: var(--accent-1); margin-bottom: 0.8rem;">${result.title}</h4><p style="line-height: 1.6;">${highlightedContent}</p></div>`;
                }

                resultsDiv.innerHTML = resultHTML;
            } catch (error) { console.error('Error in searchContent:', error); }
        }
    </script>
</body>
</html>
