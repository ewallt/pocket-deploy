<!-- /pocket-deploy/dashboard-ai-s01/index.html -->
<!DOCTYPE html>
<html lang="en">
<head><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>AI — Series s01 Dashboard</title>
<style>
:root{--bg:#0b1020;--panel:#0f172a;--ink:#e5e7eb;--muted:#94a3b8;--brand:#60a5fa;--border:#1f2940}
@media(prefers-color-scheme:light){:root{--bg:#f5f7fb;--panel:#fff;--ink:#1b2a41;--muted:#34495e;--brand:#2563eb;--border:#e3e9f3}}
*{box-sizing:border-box}body{margin:0;background:var(--bg);color:var(--ink);font:16px/1.6 system-ui,-apple-system,Segoe UI,Inter,Arial;padding:2rem}
.c{max-width:880px;margin:0 auto;background:var(--panel);border:1px solid var(--border);border-radius:14px;box-shadow:0 6px 24px rgba(0,0,0,.25)}
.top{padding:.75rem 1rem;border-bottom:1px solid var(--border);text-align:right}.top a{color:var(--muted);text-decoration:none}.top a:hover{color:var(--brand)}
.h{padding:1.4rem 1.6rem;border-bottom:1px solid var(--border)}.h h1{margin:0;font-weight:700;font-size:1.55rem}.h p{margin:.5rem 0 0;color:var(--muted)}
.g{display:grid;gap:1rem;padding:1.25rem}.a{display:block;padding:1rem 1.2rem;border:1px solid var(--border);border-radius:12px;text-decoration:none;color:var(--ink);background:rgba(255,255,255,.02)}
.a h3{margin:.2rem 0 .4rem;font-size:1.08rem;color:var(--brand)}.a p{margin:0;color:var(--muted)}.a:hover{border-color:var(--brand);transform:translateY(-1px);box-shadow:0 8px 20px rgba(37,99,235,.15)}
</style></head>
<body>
<main class="c">
  <div class="top"><a href="/pocket-deploy/dashboard-library-ai/">← Library</a></div>
  <header class="h"><h1>Series s01 — Before the Transformer Breakthrough</h1><p>Foundations and bottlenecks that set the stage for “Attention Is All You Need”.</p></header>
  <section class="g">
    <a class="a" href="/pocket-deploy/ai-s01-1/"><h3>1 — Foundations & Frictions</h3><p>From n-grams and CNN/RNN stacks to the limits that attention would later address.</p></a>
    <a class="a" href="/pocket-deploy/ai-s01-2/"><h3>2 — Sequence Models Under Strain</h3><p>Long-range dependencies, vanishing gradients, and parallelism walls.</p></a>
    <a class="a" href="/pocket-deploy/ai-s01-3/"><h3>3 — Data, Compute, and Serving</h3><p>Pipelines, distributed training, and inference realities in the pre-transformer era.</p></a>
    <a class="a" href="/pocket-deploy/ai-s01-4/"><h3>4 — Representation & Alignment Seeds</h3><p>Word vectors, early attention, and the precursors of modern alignment.</p></a>
    <a class="a" href="/pocket-deploy/ai-s01-5/"><h3>5 — Why 2017 Was Catalytic</h3><p>Converging ideas and constraints that made the transformer inevitable.</p></a>
  </section>
</main>
</body>
</html>
