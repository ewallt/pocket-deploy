<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Foundations: Skills & Tools Pathway</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.tailwindcss.com/3.4.1?plugins=typography"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&family=Lato:wght@400;700&display=swap" rel="stylesheet">
    <style>
        /* Default Theme: Newspaper */
        :root {
            --bg-gradient: #fdfdf8;
            --text: #1c1c1c;
            --accent-text: #8c1c13;
            --nav-bg: #f1f1eb;
            --nav-border: #dcdcd3;
            --nav-text: #1c1c1c;
            --nav-hover-bg: #e5e5dd;
            --nav-active-bg: #dcdcd3;
            --nav-active-text: #1c1c1c;
            --prose-text: var(--text);
            --prose-headings: var(--accent-text);
            --prose-links: var(--accent-text);
            --prose-bold: var(--text);
            font-family: 'Merriweather', serif;
        }

        .theme-emerald-paper, .theme-cyber-blue, .theme-emerald-gold {
            font-family: 'Lato', sans-serif;
        }
        
        body {
            background: var(--bg-gradient);
            color: var(--text);
            min-height: 100vh;
        }

        .ui-bg { background-color: var(--nav-bg); }
        .ui-border { border-color: var(--nav-border); }
        .text-primary { color: var(--text); }
        .text-accent { color: var(--accent-text); }

        .tab-button {
            background-color: var(--nav-bg);
            color: var(--nav-text);
            border-bottom: 3px solid transparent;
        }
        .tab-button:hover, .tab-button:focus-visible {
            background-color: var(--nav-hover-bg);
        }
        .tab-button.tab-active {
            background-color: var(--nav-active-bg);
            color: var(--nav-active-text);
            border-bottom-color: var(--accent-text);
        }

        .settings-button { background-color: var(--nav-hover-bg); }
        .settings-button:hover { opacity: 0.8; }
        *:focus-visible { outline: 3px solid var(--accent-text); outline-offset: 2px; }

        .prose { color: var(--prose-text); }
        .prose h2, .prose h3, .prose a, .prose strong { color: var(--prose-headings); }
        .prose p.lead { color: var(--prose-text); }
    </style>
</head>
<body class="transition-colors duration-300">
    <div class="container mx-auto px-4 py-6 max-w-7xl">
        <header id="app-header" class="ui-bg border ui-border rounded-lg shadow-lg p-6 mb-6"></header>
        <nav id="app-tabs" class="ui-bg border ui-border rounded-lg shadow-lg mb-6" role="tablist" aria-label="Main navigation"></nav>
        <main id="app-panels" class="ui-bg border ui-border rounded-lg shadow-lg p-6 md:p-8"></main>
        
        <div id="settingsModal" class="fixed inset-0 bg-black bg-opacity-50 hidden z-50 flex items-center justify-center p-4" role="dialog" aria-modal="true" aria-labelledby="settings-title">
            <div class="ui-bg border ui-border rounded-lg p-6 max-w-md w-full shadow-2xl">
                <h2 id="settings-title" class="text-xl font-bold text-accent mb-4">Display Settings</h2>
                <div class="space-y-4">
                    <div>
                        <label for="themeSelect" class="block text-primary font-semibold mb-2">Theme</label>
                        <select id="themeSelect" class="w-full px-3 py-2 rounded ui-bg border ui-border text-primary">
                        </select>
                    </div>
                </div>
                <div class="flex justify-end space-x-3 mt-6">
                    <button id="closeSettings" class="px-4 py-2 rounded text-primary hover:opacity-80">Close</button>
                </div>
            </div>
        </div>
    </div>

    <!-- Data Island -->
    <script type="application/json" id="app-data">
    {
      "ai-course": {
        "title": "AI Foundations: Skills & Tools Pathway",
        "description": "An 8-unit course that builds practical AI literacy from core concepts and data, through models and neural networks, to NLP, vision, tooling, and deployment.",
        "categories": {
          "unit-1-key-concepts": { "display_order": 10, "name": "Unit 1: What Is AI? Key Concepts and Terminology", "display_name": "Unit 1", "paragraphs": [ { "heading": "Defining Artificial Intelligence", "content": "Artificial Intelligence (AI) refers to the design of computer systems that can perform tasks which, if a human carried them out, would be considered intelligent. These tasks include recognizing patterns in data, making predictions, solving problems, and understanding natural language. Unlike traditional software that relies on explicit programming rules, AI systems often learn from examples and improve over time as they are exposed to more data. This distinction between static rules and adaptive systems is at the heart of AI’s transformative power. When we talk about AI today, we are usually referring to machine learning systems—algorithms that adjust their internal parameters to better map inputs to outputs. For example, rather than programming every detail of how to recognize a cat in an image, engineers provide thousands of labeled cat photos, and the system learns the common features on its own. This approach has led to breakthroughs in language translation, medical diagnostics, and recommendation systems, reshaping entire industries. Understanding this definition provides a grounding for everything that follows in this course." }, { "heading": "Narrow vs. General Intelligence", "content": "One of the most important distinctions in AI is between narrow intelligence and general intelligence. Narrow AI, sometimes called weak AI, is designed to perform a specific task or a small range of tasks. Examples include voice assistants like Siri or Alexa, spam filters for email, and facial recognition in photo libraries. These systems can perform their narrow tasks extremely well but lack flexibility—your spam filter cannot drive a car, and your voice assistant cannot diagnose diseases. General AI, on the other hand, would have the ability to learn and adapt across many domains, much like a human being can. It would reason, plan, and transfer knowledge from one area to another. Despite its portrayal in movies and speculative fiction, general AI does not yet exist and remains a long-term research goal. Most of the progress and applications we see today belong firmly to the realm of narrow AI. Recognizing this difference is crucial: narrow AI has already changed the world, while general AI is still hypothetical." }, { "heading": "Rules, Machine Learning, and Heuristics", "content": "Before the dominance of machine learning, early AI research focused on rule-based systems. In such systems, experts hand-crafted rules that computers would follow. For example, a medical diagnostic system might ask a series of yes/no questions and then apply rules to suggest possible illnesses. These systems worked well in highly structured domains but often failed in messy, real-world scenarios because it was impossible to encode every exception. Machine learning took a different approach, allowing the system to discover patterns in data rather than relying entirely on pre-written rules. Heuristics, or practical shortcuts, still play a role in AI—sometimes a well-chosen heuristic can reduce computation time or guide a model’s search for solutions. In practice, many modern AI systems combine all three approaches: they use machine learning to recognize patterns, heuristics to make quick decisions, and rules to enforce boundaries or comply with regulations. This hybrid design makes them both flexible and controllable." }, { "heading": "Data, Features, and Labels", "content": "At the heart of every AI system is data. Data can take many forms: numbers in a spreadsheet, images, video, or snippets of text. Features are the aspects of that data that are used by the model to make predictions. In image recognition, features might be edges, textures, or color distributions; in natural language processing, they might be word tokens or embeddings. Labels are the ground truth values used in supervised learning—what the system is supposed to predict. For instance, in an email spam filter, the features are derived from the text of the email, and the labels are 'spam' or 'not spam.' The quality of the features and labels directly influences model performance. Poorly labeled data leads to confusion and inaccurate predictions, while well-structured data allows the system to generalize effectively. Understanding how data, features, and labels interact is essential because these choices determine whether an AI project succeeds or fails." }, { "heading": "Training vs. Inference", "content": "The life cycle of an AI model can be divided into two phases: training and inference. Training is the process by which the model learns from data. During training, algorithms adjust millions or even billions of parameters to minimize errors on the provided examples. This process is computationally intensive, often requiring specialized hardware like GPUs. Once training is complete, the model moves to inference: applying what it has learned to new, unseen data. For example, a trained image classifier may have been taught with millions of photos, but inference is when it correctly identifies a new photo uploaded by a user. Training may occur only occasionally, but inference must happen quickly and efficiently whenever the system is used. Understanding this distinction helps you grasp why companies often centralize training in data centers but deploy inference models on edge devices, phones, or browsers where speed and responsiveness matter most." }, { "heading": "Symbolic vs. Statistical Approaches", "content": "AI can be broadly divided into symbolic and statistical approaches. Symbolic AI, also called 'good old-fashioned AI,' relies on explicit representations of knowledge. It uses symbols, rules, and logic to reason about problems. Chess programs from the 1980s, for example, relied heavily on symbolic reasoning, encoding expert knowledge and searching through possibilities. Statistical AI, by contrast, focuses on learning patterns from large datasets. Machine learning and neural networks are examples of statistical approaches, relying less on explicit rules and more on probabilities. Today’s breakthroughs, from large language models to image recognition systems, come primarily from statistical AI. However, symbolic methods are still relevant. Some researchers believe hybrid systems—combining the structure of symbolic reasoning with the adaptability of statistical learning—will be necessary for building more trustworthy and interpretable AI. Knowing both traditions helps clarify the strengths and weaknesses of different approaches." }, { "heading": "Supervised, Unsupervised, and Reinforcement Learning", "content": "Machine learning is not a single technique but a family of approaches. In supervised learning, models learn from labeled examples. Given thousands of emails marked 'spam' or 'not spam,' the system learns to classify new ones. In unsupervised learning, there are no labels—models look for structure in the data, such as grouping customers into segments based on purchasing habits. Reinforcement learning is different: the system learns by interacting with an environment, receiving rewards or penalties for its actions. A reinforcement learner might play a video game, improving its strategy by maximizing its score. Each approach has strengths and limitations. Supervised learning requires costly labeled data but delivers accurate results. Unsupervised learning reveals hidden patterns but may lack clear validation. Reinforcement learning can achieve human-level or even superhuman performance in specific domains, but it is computationally expensive and data-hungry. These three paradigms form the core of most modern AI applications." }, { "heading": "Generative vs. Discriminative Models", "content": "Models can also be classified as generative or discriminative. Discriminative models focus on distinguishing between categories—they learn decision boundaries between classes. Logistic regression and support vector machines are classic discriminative models. Generative models, on the other hand, attempt to model the underlying distribution of the data itself. They can create new examples that resemble the training data. Language models that generate fluent text, or image generators like diffusion models, are generative. Both types of models have practical uses: discriminative models are often simpler and more efficient for classification tasks, while generative models power applications in creativity, simulation, and unsupervised learning. Importantly, generative and discriminative methods are not mutually exclusive. In some cases, combining them produces more robust systems, such as semi-supervised learning where generative models help compensate for limited labeled data." }, { "heading": "Bias, Fairness, and Accountability", "content": "AI systems reflect the data they are trained on and the decisions made by their designers. This can lead to bias—systematic errors that disadvantage particular groups. For instance, a facial recognition system trained mostly on lighter-skinned individuals may perform poorly on darker-skinned individuals. Fairness in AI is not just a technical challenge but a social one, requiring careful dataset design, algorithmic audits, and diverse perspectives in development. Accountability means ensuring that when systems fail or cause harm, there are mechanisms to trace why decisions were made and to assign responsibility. This might include maintaining model documentation, audit trails, or even regulatory oversight. Addressing bias, fairness, and accountability from the outset prevents real-world harm and builds trust in AI deployments. Ignoring these issues, on the other hand, risks amplifying social inequalities and undermining confidence in the technology." }, { "heading": "AI System Boundaries", "content": "It is easy to think of AI as just the model itself, but in practice an AI system encompasses much more. Inputs must be collected, cleaned, and validated. Models must be trained, evaluated, and deployed into environments with specific constraints. Post-processing often shapes model outputs to meet business or ethical goals, while monitoring systems track performance over time to detect drift or anomalies. Human oversight, too, is an essential component, ensuring that AI complements rather than replaces critical decision-making. For example, in a medical AI system, predictions must be checked by trained professionals, with clear channels for escalation if errors occur. Thinking of AI in terms of complete systems, rather than isolated algorithms, helps practitioners anticipate challenges and design more reliable solutions. This system-level perspective concludes our foundational overview and prepares you for deeper dives in the modules to come." } ] },
          "unit-2-data": { "display_order": 20, "name": "Unit 2: Data — The Fuel of AI", "display_name": "Unit 2", "paragraphs": [ { "heading": "Data Types and Modalities", "content": "AI systems learn from many kinds of data, and each modality carries different structure, noise patterns, and preprocessing needs. Structured data (tables) organizes information into rows and columns with clear types; it favors feature engineering, tree ensembles, and linear models. Text is sequential and sparse; tokenization and embeddings are key before applying language models. Images and video are high-dimensional arrays with spatial or spatiotemporal correlations; convolutions or attention backbones extract patterns. Audio is a time series that often benefits from spectral transforms (e.g., mel spectrograms). Logs and events arrive as semi-structured streams that require parsing and sessionization. Graphs encode entities and relationships; graph neural networks can leverage connectivity for prediction and recommendation. Selecting pipelines and models that respect a modality’s structure is the first lever on performance, reliability, and cost. Misaligned choices—like treating raw pixels as tabular features—waste signal and invite brittleness." }, { "heading": "Sourcing and Collection", "content": "Where your data comes from determines what your model will learn. Enumerate sources (product telemetry, vendor datasets, public corpora, user uploads, sensors) and document the legal basis and consent status for each. Define inclusion criteria, sampling methods, and time windows to prevent leakage from the future and to mirror the production environment. Establish versioned data pipelines with clear owners so that upstream schema or logging changes trigger alerts rather than silent failures. Prefer privacy-preserving defaults—collect the minimum needed, remove direct identifiers early, and hash or tokenize where feasible. For human-entered text or labels, capture annotator IDs (pseudonymous) and timestamps to analyze consistency over time. If you plan online learning or feedback loops, design event instrumentation up front so ground-truth signals are available when you need them. Good collection practices create predictable distributions and make downstream governance tractable." }, { "heading": "Labeling and Annotation", "content": "Supervised learning depends on high-quality labels, and annotation is a process that can be engineered for accuracy and speed. Start with explicit task definitions, decision rubrics, and canonical examples—what counts as correct, borderline, or out-of-scope. Train annotators with quiz rounds and inter-rater reliability checks (e.g., Cohen’s kappa) to calibrate understanding. Use redundancy (multiple annotators per item) and active learning to route the most ambiguous examples to senior reviewers. Build gold-standard test sets into the labeling tool to monitor drift in annotator quality. Capture rationales when feasible; short notes explaining a choice help resolve disagreements later and can seed explanation datasets. Automate quality flags for adversarial or spammy submissions. Finally, close the loop: surface common annotation errors to improve the rubric, and update the tool’s UI to reduce misclicks or fatigue. Labels produced by this disciplined workflow are measurably more reliable." }, { "heading": "Data Splits: Train, Validation, and Test", "content": "Honest evaluation begins with disciplined dataset splitting. Create non-overlapping train, validation, and test sets that represent the production distribution and honor natural boundaries (users, sessions, time). For user-facing systems, use group-aware splits so that the same person or entity never appears across splits; otherwise, leakage will inflate metrics. For time-sensitive problems, perform temporal splits (train on the past, validate on the recent past, test on the near future) to simulate deployment. Lock the test set and avoid peeking during iteration; use the validation set for model selection and hyperparameter tuning. Record the random seeds and sampling logic so splits are reproducible. When data is scarce, consider cross-validation but still maintain a final untouched test set. This discipline prevents overfitting to evaluation data and yields performance estimates that correlate with real-world impact." }, { "heading": "Feature Engineering and Representations", "content": "Representations are the lens through which models see the world. In tabular domains, well-crafted features—ratios, differences, time since last event, target encodings with leakage-safe schemes—often beat complex architectures. For text, subword tokenization and pretrained embeddings encode semantics; for images, pretrained backbones produce compact feature maps; for graphs, node and edge embeddings summarize structure. Normalize numeric features, standardize units, and handle missing values explicitly rather than allowing implicit defaults to skew learning. Document every transformation in a schema contract so training and inference pipelines stay in lockstep. Favor deterministic, versioned transforms; when using learned representations (e.g., an embedding model), pin its version and record training data lineage. The right representation simplifies the decision boundary, boosts sample efficiency, and supports interpretability and debugging." }, { "heading": "Augmentation, Balancing, and Hard Negatives", "content": "Augmentation synthetically expands data diversity and improves generalization when done carefully. In vision, use flips, crops, color jitter, cutout, and mixup; in text, leverage paraphrasing, back-translation, or noise injection while guarding label integrity. For imbalanced datasets, combine resampling (oversample minority classes or undersample majority) with class-aware loss weighting; monitor that recall improves without collapsing precision. Mine hard negatives—examples that look similar to positives but should be rejected—to sharpen boundaries for ranking and detection tasks. Use curriculum schedules: train first on clean, easy examples to learn the basics, then gradually introduce harder or noisier samples. Track augmentation parameters as part of your experiment config; aggressive settings can distort the distribution and degrade real-world performance. Done right, augmentation and balancing turn limited data into robust signal." }, { "heading": "Quality Assurance and Data Validation", "content": "Data quality issues silently erode model performance. Build validation checks at ingestion: schema conformity, type ranges, categorical domain membership, and referential integrity. Add distributional tests—summary stats, histograms, and population stability indices—to detect shifts versus a baseline dataset. Scan for duplicates and near-duplicates that can leak information between splits. Create unit tests for feature logic (e.g., time windows, aggregations) and property-based tests that stress boundaries. For labels, measure agreement rates and maintain a confusion matrix against gold standards to spot systemic mislabels. Surface anomalies to dashboards and fail fast when critical thresholds are exceeded. Finally, stage changes: run new data through a shadow pipeline and compare predictions to production before switching over. Treat data quality like a first-class CI/CD concern, not an afterthought." }, { "heading": "Drift, Monitoring, and Feedback Loops", "content": "Production data rarely stays static. Monitor for covariate drift (input features shift), prior drift (class frequencies change), and concept drift (the mapping from inputs to outputs evolves). Track feature distributions, calibration curves, and performance by slice (region, device, cohort). Use canaries and rolling windows to catch regressions early. When drift is detected, choose the right response: recalibrate thresholds, refresh features, or retrain with recent data. Build feedback loops—user ratings, click signals, human-in-the-loop review—to accumulate fresh labels, but guard against confirmation bias and self-reinforcement. Archive snapshots of data and models so that incidents can be reproduced and investigated. A robust monitoring practice turns deployment from a one-time event into an ongoing learning system that improves with use." }, { "heading": "Bias, Representativeness, and Harm Analysis", "content": "Data reflects the world’s imbalances and omissions; without care, models will scale them. Audit representativeness across salient attributes (e.g., geography, device class, language variety) and key edge cases. Build targeted evaluation sets that stress long-tail scenarios, and report metrics by slice rather than only global averages. Where appropriate, use reweighting, stratified sampling, or targeted data collection to close gaps. Conduct harm analysis: who could be disproportionately impacted by errors, and how severe are those harms? Document known limitations and intended use, and add enforcement layers (e.g., confidence thresholds, escalation to human review) in higher-risk contexts. Bias mitigation is not a one-off technique but a lifecycle practice spanning collection, labeling, modeling, and monitoring." }, { "heading": "Governance, Privacy, and Documentation", "content": "Treat datasets as governed artifacts with owners, access policies, and audit trails. Minimize personal data, apply de-identification where possible, and restrict linkage keys. Respect jurisdictional requirements for consent, retention, and data subject rights. Maintain a living dataset card that captures purpose, composition, sources, collection methods, labeling guidelines, preprocessing, splits, known issues, and ethical considerations. Version both raw dumps and derived features so that experiments can be reproduced and incidents investigated. Establish change management: when a source or schema evolves, run compatibility tests and communicate downstream impacts. Good documentation and governance reduce operational risk, accelerate onboarding, and build trust with stakeholders, regulators, and, ultimately, users." } ] },
          "unit-3-algorithms-models": { "display_order": 30, "name": "Unit 3: Algorithms and Models", "display_name": "Unit 3", "paragraphs": [{"heading":"Learning Paradigms", "content":"Supervised, unsupervised, self-supervised, semi-supervised, and reinforcement learning provide different supervision signals. Choose based on data availability and task constraints."}] },
          "unit-4-neural-networks": { "display_order": 40, "name": "Unit 4: Building and Training Neural Networks", "display_name": "Unit 4", "paragraphs": [{"heading":"Neurons, Layers, and Computation Graphs", "content":"Neural nets compose linear transforms with non-linear activations. Computation graphs track operations so gradients can be computed automatically."}] },
          "unit-5-nlp-essentials": { "display_order": 50, "name": "Unit 5: Working with Text — NLP Essentials", "display_name": "Unit 5", "paragraphs": [{"heading":"Text Preprocessing and Tokenization", "content":"Normalize, clean, and segment text into tokens. Subword tokenizers (BPE/WordPiece) balance vocabulary size with coverage for rare words."}] },
          "unit-6-vision-systems": { "display_order": 60, "name": "Unit 6: Working with Images and Video — Vision Systems", "display_name": "Unit 6", "paragraphs": [{"heading":"Pixels, Channels, and Datasets", "content":"Images are tensors with spatial and channel dimensions; videos add time. Curate datasets with varied lighting, viewpoints, and backgrounds to avoid brittle models."}] },
          "unit-7-tools-frameworks": { "display_order": 70, "name": "Unit 7: Tools, Frameworks, and Platforms", "display_name": "Unit 7", "paragraphs": [{"heading":"Framework Landscape", "content":"PyTorch and TensorFlow dominate deep learning; JAX is rising for research. Scikit-learn remains a staple for classical ML, especially on tabular data."}] },
          "unit-8-deployment": { "display_order": 80, "name": "Unit 8: Deploying AI — From Research to Real-World Systems", "display_name": "Unit 8", "paragraphs": [{"heading":"Product Framing and KPIs", "content":"Define user outcomes and business KPIs before modeling. Align metrics with real costs (false positives/negatives) and acceptable risk."}] }
        }
      }
    }
    </script>

    <script defer>
    document.addEventListener('DOMContentLoaded', () => {

        const THEMES = {
          'newspaper': { 
            name: 'Newspaper', 
            type: 'classic', 
            isDark: false 
          },
          'emerald-paper': {
            name: 'Emerald Paper', 
            type: 'variable', 
            isDark: false,
            vars: {
              '--bg-gradient': '#f7fbf9', '--text': '#1e2b28', '--accent-text': '#0f7f6d', '--nav-bg': '#e7f3ef',
              '--nav-border': '#86c8ba', '--nav-text': '#1e2b28', '--nav-hover-bg': '#d7ece6', '--nav-active-bg': '#bfe3d9',
              '--nav-active-text': '#1e2b28', '--prose-text': '#1e2b28', '--prose-headings': '#0f7f6d'
            }
          },
          'cyber-blue': {
            name: 'Cyber Night', 
            type: 'variable', 
            isDark: true,
            vars: {
              '--bg-gradient': 'rgb(2, 6, 23)',
              '--text': 'rgb(203, 213, 225)',
              '--accent-text': 'rgb(203, 213, 225)',
              '--nav-bg': 'rgb(30, 41, 59)',
              '--nav-border': 'rgb(51, 65, 85)',
              '--nav-text': 'rgb(203, 213, 225)',
              '--nav-hover-bg': 'rgb(15, 23, 42)',
              '--nav-active-bg': 'rgb(51, 65, 85)',
              '--nav-active-text': '#FFFFFF',
              '--prose-text': 'rgb(203, 213, 225)',
              '--prose-headings': '#FFFFFF'
            }
          },
          'emerald-gold': {
            name: 'Emerald/Gold', 
            type: 'variable', 
            isDark: true,
            vars: {
              '--bg-gradient': 'linear-gradient(135deg,#022c22 0%,#064e3b 60%,#065f46 100%)', '--text': '#ecfdf5',
              '--accent-text': '#f0c475', '--nav-bg': '#064e3b', '--nav-border': '#d4a24c', '--nav-text': '#ecfdf5',
              '--nav-hover-bg': '#065f46', '--nav-active-bg': '#0b3d31', '--nav-active-text': '#f0c475',
              '--prose-text': '#a7f3d0', '--prose-headings': '#ecfdf5'
            }
          }
        };

        const app = {
            root: document.documentElement,
            header: document.getElementById('app-header'),
            tabs: document.getElementById('app-tabs'),
            panels: document.getElementById('app-panels'),
            settings: {
                modal: document.getElementById('settingsModal'),
                closeBtn: document.getElementById('closeSettings'),
                themeSelect: document.getElementById('themeSelect')
            }
        };

        const state = { activeTab: null, theme: 'newspaper' };

        const loadState = () => {
            state.theme = localStorage.getItem('appTheme') || 'newspaper';
            state.activeTab = localStorage.getItem('activeTab');
        };

        const saveState = () => {
            localStorage.setItem('appTheme', state.theme);
            localStorage.setItem('activeTab', state.activeTab);
        };

        const applyTheme = (themeKey) => {
            const theme = THEMES[themeKey];
            if (!theme) return;

            app.root.className = '';
            app.root.style.cssText = '';

            if (theme.type === 'variable' && theme.vars) {
                for (const [key, value] of Object.entries(theme.vars)) {
                    app.root.style.setProperty(key, value);
                }
                app.root.classList.add(`theme-${themeKey}`);
            }

            state.theme = themeKey;
            if (app.settings.themeSelect.value !== themeKey) {
                app.settings.themeSelect.value = themeKey;
            }
            saveState();
        };

        const populateThemeSelector = () => {
            app.settings.themeSelect.innerHTML = Object.entries(THEMES).map(([key, theme]) => 
                `<option value="${key}">${theme.name}</option>`
            ).join('');
        };

        const loadAndTransformData = () => {
            try {
                const rawData = JSON.parse(document.getElementById('app-data').textContent);
                const course = rawData['ai-course'];
                const units = Object.entries(course.categories).map(([id, unitData]) => ({ id, ...unitData }))
                    .sort((a, b) => a.display_order - b.display_order);
                return { meta: { title: course.title, description: course.description }, units };
            } catch (e) {
                console.error("Failed to load or transform app data:", e);
                return null;
            }
        };
        
        const data = loadAndTransformData();
        if (!data) return;

        const renderHeader = () => {
            app.header.innerHTML = `
                <div class="flex justify-between items-start gap-4">
                    <div>
                        <h1 class="text-3xl font-bold text-accent">${data.meta.title}</h1>
                        <p class="mt-2 text-primary/80">${data.meta.description}</p>
                    </div>
                    <button id="settingsBtn" class="flex-shrink-0 p-3 rounded-lg settings-button transition-opacity" aria-label="Display Settings">
                        <span class="text-2xl text-accent">⚙️</span>
                    </button>
                </div>`;
        };
        
        const renderTabs = () => {
            app.tabs.innerHTML = `<div class="flex flex-wrap">${
                data.units.map(unit => `
                    <button role="tab" aria-selected="false" aria-controls="${unit.id}-panel" id="${unit.id}-tab"
                            class="px-5 py-3 font-semibold transition-colors tab-button">
                        ${unit.display_name}
                    </button>`
                ).join('')
            }</div>`;
        };

        const renderPanels = () => {
            app.panels.innerHTML = data.units.map(unit => {
                const introHTML = unit.introduction ? `<p class="lead">${unit.introduction}</p>` : '';
                const paragraphsHTML = (unit.paragraphs || []).map(p => `
                    <h3>${p.heading}</h3>
                    <p>${p.content}</p>
                `).join('');
                const proseClasses = THEMES[state.theme].isDark ? 'prose prose-lg max-w-none prose-invert' : 'prose prose-lg max-w-none';
                return `
                    <div role="tabpanel" id="${unit.id}-panel" aria-labelledby="${unit.id}-tab" hidden>
                        <div class="${proseClasses}">
                            <h2>${unit.name}</h2>
                            ${introHTML}
                            ${paragraphsHTML}
                        </div>
                    </div>`;
            }).join('');
        };

        const switchTab = (tabId) => {
            if (!data.units.some(u => u.id === tabId)) {
                tabId = data.units[0]?.id;
            }
            if (!tabId) return;

            app.tabs.querySelectorAll('[role="tab"]').forEach(tab => {
                const isActive = tab.id === `${tabId}-tab`;
                tab.setAttribute('aria-selected', isActive);
                tab.classList.toggle('tab-active', isActive);
            });

            app.panels.querySelectorAll('[role="tabpanel"]').forEach(panel => {
                panel.hidden = panel.id !== `${tabId}-panel`;
            });
            
            state.activeTab = tabId;
            saveState();
        };

        const setupEventListeners = () => {
            app.tabs.addEventListener('click', e => {
                const tab = e.target.closest('[role="tab"]');
                if (tab) switchTab(tab.id.replace('-tab', ''));
            });

            app.header.addEventListener('click', e => {
                if (e.target.closest('#settingsBtn')) {
                    app.settings.modal.classList.remove('hidden');
                    app.settings.themeSelect.focus();
                }
            });
            
            const closeModal = () => {
                app.settings.modal.classList.add('hidden');
                document.getElementById('settingsBtn')?.focus();
            };
            app.settings.closeBtn.addEventListener('click', closeModal);
            app.settings.modal.addEventListener('keydown', e => {
                if (e.key === 'Escape') closeModal();
            });

            app.settings.themeSelect.addEventListener('change', (e) => {
                applyTheme(e.target.value);
                renderPanels();
                const activePanel = document.getElementById(`${state.activeTab}-panel`);
                if(activePanel) activePanel.hidden = false;
            });
        };

        const init = () => {
            loadState();
            populateThemeSelector();
            applyTheme(state.theme);
            renderHeader();
            renderTabs();
            renderPanels();
            setupEventListeners();
            switchTab(state.activeTab || data.units[0]?.id);
        };

        init();
    });
    </script>
</body>
</html>
