<!DOCTYPE html>
<html lang="en">
<head><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Neural Topic Models — Series 1 Dashboard</title>
<style>:root{--bg:#0f1216;--panel:#14181d;--ink:#e6e8eb;--muted:#9aa7b3;--brand:#8aa0b3;--border:#222831}@media(prefers-color-scheme:light){:root{--bg:#f7f5f1;--panel:#ffffff;--ink:#262a2f;--muted:#5b6d7a;--brand:#5b6d7a;--border:#e6e2da}}*{box-sizing:border-box}body{margin:0;background:var(--bg);color:var(--ink);font:16px/1.6 system-ui,-apple-system,Segoe UI,Inter,Arial;padding:2rem}.c{max-width:880px;margin:0 auto;background:var(--panel);border:1px solid var(--border);border-radius:14px;box-shadow:0 6px 24px rgba(0,0,0,.25)}.navtop{padding:.75rem 1rem;border-bottom:1px solid var(--border);text-align:right}.navtop a{text-decoration:none;color:var(--muted);font-size:.9rem}.navtop a:hover{color:var(--brand)}.h{padding:1.5rem 1.75rem;border-bottom:1px solid var(--border)}.h h1{margin:0;font:700 1.6rem/1.2 system-ui,-apple-system,Segoe UI,Inter,Arial}.h p{margin:.5rem 0 0;color:var(--muted)}.g{display:grid;gap:1rem;padding:1.25rem}.a{display:block;padding:1rem 1.25rem;border:1px solid var(--border);border-radius:12px;text-decoration:none;color:var(--ink);background:rgba(255,255,255,.02)}.a:hover{border-color:var(--brand);box-shadow:0 8px 20px rgba(138,160,179,.15);transform:translateY(-1px)}.a h3{margin:.2rem 0 .4rem;font-size:1.08rem;color:var(--brand)}.a p{margin:0;color:var(--muted)}</style></head>
<body><main class="c">
<div class="navtop"><a href="/pocket-deploy/dashboard-library-neural-topic-models/">← Library</a></div>
<header class="h"><h1>Neural Topic Models — Series 1</h1><p>Foundations & the Bridge: classical topic modeling, why it struggles, and how neural methods extend it.</p></header>
<section class="g">
  <a class="a" href="/pocket-deploy/neural-topic-models-1-1/"><h3>Part 1 — Why Go Neural for Topics?</h3><p>From LDA’s strengths and limits to amortized inference, richer priors, and flexible likelihoods.</p></a>
  <a class="a" href="/pocket-deploy/neural-topic-models-1-2/"><h3>Part 2 — VAEs as Topic Models</h3><p>The generative story, ELBO intuition, logistic-normal tricks, and practical training concerns.</p></a>
  <a class="a" href="/pocket-deploy/neural-topic-models-1-3/"><h3>Part 3 — Neural Dirichlet & ProdLDA</h3><p>Replacing Dirichlet with logistic-normal; sharpness vs stability; product-of-experts intuition.</p></a>
  <a class="a" href="/pocket-deploy/neural-topic-models-1-4/"><h3>Part 4 — Contextualized Topic Models</h3><p>Marrying BoW with embeddings; separating content from context; multilingual and domain shifts.</p></a>
  <a class="a" href="/pocket-deploy/neural-topic-models-1-5/"><h3>Part 5 — Evaluation & Pitfalls</h3><p>Coherence, diversity, stability, and why interpretability needs more than a single metric.</p></a>
</section>
</main></body>
</html>
